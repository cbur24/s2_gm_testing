{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d77223-6f80-4053-ad57-29071eb7c291",
   "metadata": {},
   "source": [
    "# Can we improve cloud masking?\n",
    "\n",
    "For example:\n",
    "* Thresholding blue bands?\n",
    "* Utilising S2Cloudless probability layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cd3712-9913-4565-9b00-d3eaaf0fe1f9",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4644801-21a5-461e-8d8d-6fd7ffe6b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import datacube\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from odc.geo.xr import assign_crs\n",
    "import matplotlib.pyplot as plt\n",
    "from odc.algo import mask_cleanup\n",
    "from odc.geo.geom import Geometry\n",
    "from odc.algo import xr_quantile\n",
    "from odc.algo._masking import mask_cleanup\n",
    "from odc.algo import geomedian_with_mads\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jovyan/git/dea-notebooks/Tools/')\n",
    "from dea_tools.datahandling import load_ard\n",
    "from dea_tools.dask import create_local_dask_cluster\n",
    "from dea_tools.plotting import rgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9761c-e2fa-440d-9552-e14d372dfc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = create_local_dask_cluster(return_client=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc89342-cd9a-4fef-8951-5fec1dd118d3",
   "metadata": {},
   "source": [
    "## Analysis Parameters\n",
    "\n",
    "Locations for testing:\n",
    "\n",
    "* 'x33y26' # Central Aus with salt lakes\n",
    "* 'x19y18' # Esperance crops and sand dunes\n",
    "* 'x42y38' # Qld tropical forests\n",
    "* 'x41y12' # Complex coastal in Vic.\n",
    "* 'x39y13' # Melbourne city and bay+crops\n",
    "* 'x39y09' # West tassie\n",
    "* 'x40y07' # southwest tassie\n",
    "* 'x33y26' # Central Aus with salt lakes\n",
    "* 'x31y43' # Tropical NT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870fdcaa-7010-4e0b-88d6-6e8583e22683",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_code = ['x42y38']\n",
    "\n",
    "time='2022'\n",
    "resolution=(-30,30)\n",
    "dask_chunks = dict(x=1024, y=1024)\n",
    "\n",
    "s2cloudless_threshold = 0.4\n",
    "cp_threshold = 0.1\n",
    "mask_filters = [(\"opening\", 2), (\"dilation\", 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f472a-a763-4626-8716-02f5dddd9150",
   "metadata": {},
   "source": [
    "## Set up dc query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35526ebf-8f38-44e4-8a96-744a1f0beae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to dc\n",
    "dc = datacube.Datacube(app='s2_gm_test')\n",
    "\n",
    "# Create a reusable query\n",
    "query = {\n",
    "    'time': time,\n",
    "    'resolution': resolution,\n",
    "    'dask_chunks' : dask_chunks,\n",
    "    'group_by': 'solar_day',\n",
    "    'output_crs': 'EPSG:3577',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220acf87-b31b-4597-bc4b-79fb74a664b2",
   "metadata": {},
   "source": [
    "## Open tiles and select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f3bdee-0467-4103-b500-46ffe2bcf708",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('~/gdata1/data/albers_grids/ga_summary_grid_c3.geojson')\n",
    "\n",
    "gdf = gdf[gdf['region_code'].isin(region_code)]\n",
    "\n",
    "geom = Geometry(geom=gdf.iloc[0].geometry, crs=gdf.crs)\n",
    "\n",
    "query.update({'geopolygon': geom})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ad953-0fe5-44b7-97bb-2b380f50036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.explore(\n",
    "#         tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "#         attr = 'Esri',\n",
    "#         name = 'Esri Satellite',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8836fa7d-0c75-4516-a62e-348ab29a964e",
   "metadata": {},
   "source": [
    "## Load long-term cloud-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35b6956-d451-4d5c-86aa-419bddd397f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_probs = load_ard(dc=dc,\n",
    "             products=['ga_s2am_ard_3', 'ga_s2bm_ard_3', 'ga_s2cm_ard_3'],\n",
    "             measurements=['oa_s2cloudless_prob'],\n",
    "             time=('2020','2025'),\n",
    "             resolution=resolution,\n",
    "             geopolygon=geom,\n",
    "             dask_chunks=dask_chunks,\n",
    "             group_by='solar_day',\n",
    "             output_crs='EPSG:3577',\n",
    "             cloud_mask='s2cloudless',\n",
    "             resampling=\"cubic\",\n",
    "             verbose=False,\n",
    "             mask_pixel_quality=False,\n",
    "             mask_contiguity=True,\n",
    "             skip_broken_datasets=True,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea934aee-8ab0-4bcf-9e6a-b3690bede2c5",
   "metadata": {},
   "source": [
    "## Compute quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d7c966-bc51-4570-9d1a-66da20280b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prob_quantiles = xr_quantile(cp_probs[['oa_s2cloudless_prob']].chunk(dict(time=-1)), quantiles=[0.1], nodata=np.nan).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5dc7c-34e5-4b59-9e8a-4ac1d9e19025",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2, figsize=(14,6), layout='constrained', sharey=True)\n",
    "\n",
    "# for q,ax in zip(prob_quantiles['quantile'].values, axes.ravel()):\n",
    "prob_quantiles['oa_s2cloudless_prob'].sel(quantile=0.1).plot.imshow(ax=ax[0], vmin=0, vmax=0.4, add_labels=False)\n",
    "ax[0].set_title(f'2020-2025 cloud probability quantile=0.1');\n",
    "\n",
    "(prob_quantiles['oa_s2cloudless_prob'].sel(quantile=0.1) > 0.1).plot.imshow(ax=ax[1], add_labels=False)\n",
    "ax[1].set_title(f'quantile=0.1 > 0.1');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d426948-c889-469c-9f34-fdec067c863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_quantiles['oa_s2cloudless_prob'].sel(quantile=0.1).odc.explore(vmin=0, vmax=0.1,\n",
    "#     tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "#     attr = 'Esri',\n",
    "#     name = 'Esri Satellite'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877d3518-aa1d-4ac2-8259-e7a84f95b06e",
   "metadata": {},
   "source": [
    "## Load SR data\n",
    "\n",
    "load masked and unmasked so we can compare the enhanced cloud mask with the standard mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd0671-5b14-4e64-9635-d1069cd722d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_masked = load_ard(dc=dc,\n",
    "             products=['ga_s2am_ard_3', 'ga_s2bm_ard_3', 'ga_s2cm_ard_3'],\n",
    "             measurements=['nbart_green', 'nbart_red', 'nbart_blue'],\n",
    "             cloud_mask='s2cloudless',\n",
    "             resampling={\"oa_s2cloudless_mask\": \"nearest\", \"*\": \"cubic\"},\n",
    "             verbose=False,\n",
    "             mask_pixel_quality=True,\n",
    "             mask_contiguity=True,\n",
    "             skip_broken_datasets=True,\n",
    "             **query\n",
    "            )\n",
    "\n",
    "s2_unmasked = load_ard(dc=dc,\n",
    "             products=['ga_s2am_ard_3', 'ga_s2bm_ard_3', 'ga_s2cm_ard_3'],\n",
    "             measurements=['nbart_green', 'nbart_red', 'nbart_blue', 'oa_s2cloudless_prob'],\n",
    "             cloud_mask='s2cloudless',\n",
    "             resampling={\"*\": \"cubic\"},\n",
    "             verbose=False,\n",
    "             mask_pixel_quality=False,\n",
    "             mask_contiguity=True,\n",
    "             skip_broken_datasets=True,\n",
    "             **query\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0960cf0-d8c3-406c-a29d-06003cbc56c3",
   "metadata": {},
   "source": [
    "## Percentiles of cloud probability\n",
    "\n",
    "* Calculate an all-of-time 10% quantile of cloud probabilities to identify pixels that consistently overclassify cloud - e.g. bright beaches, urban), and only consider a pixel as cloud if it is X% cloudier than that threshold)\n",
    "* Default threshold is 0.4, aim to increase this where long-term lower quantile is near this threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83cbc93-cdc1-4364-a5f5-3764ab866499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_quantiles = xr_quantile(s2_unmasked[['oa_s2cloudless_prob']].chunk(dict(time=-1)), quantiles=[0.05, 0.1], nodata=np.nan).compute()\n",
    "\n",
    "# fig,axes = plt.subplots(1,2, figsize=(14,6), layout='constrained', sharey=True)\n",
    "\n",
    "# for q,ax in zip(prob_quantiles['quantile'].values, axes.ravel()):\n",
    "#     prob_quantiles['oa_s2cloudless_prob'].sel(quantile=q).plot.imshow(ax=ax, vmin=0)\n",
    "#     ax.set_title(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8039934-c43d-4a08-aaa6-c58f7a4930a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(1,4, figsize=(20,6), layout='constrained', sharey=True)\n",
    "# prob_quantiles['oa_s2cloudless_prob'].sel(quantile=0.1).plot.imshow(vmin=0, vmax=0.4, ax=ax[0])\n",
    "# ax[1].set_title('10th percentile probabilities')\n",
    "\n",
    "# xr.where(prob_quantiles['oa_s2cloudless_prob'].sel(quantile=0.1)>=0.1, 1, 0).plot.imshow(ax=ax[1])\n",
    "# ax[1].set_title('10th percentile, threshold=0.1')\n",
    "\n",
    "# xr.where(prob_quantiles['oa_s2cloudless_prob'].sel(quantile=0.1)>=0.2, 1, 0).plot.imshow(ax=ax[2])\n",
    "# ax[2].set_title('10th percentile, threshold=0.2')\n",
    "\n",
    "# xr.where(prob_quantiles['oa_s2cloudless_prob'].sel(quantile=0.1)>=0.4, 1, 0).plot.imshow(ax=ax[3])\n",
    "# ax[3].set_title('10th percentile, threshold=0.4');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee9289-b1e0-45f7-ba90-4cf01e069595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xr.where(prob_quantiles['oa_s2cloudless_prob'].sel(quantile=0.1)>0.4, 1, 0).odc.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c1923-708b-4696-85ac-a5995099bc42",
   "metadata": {},
   "source": [
    "## Enhanced cloud masking with S2Cloudless probability\n",
    "\n",
    "Logics...`Consider combining the options?`\n",
    "\n",
    "`Option 1 (highly conservative)`\n",
    "1. Load long-term cloud probabilities (say five years), take the 10th percentile.\n",
    "2. Where 10th percentile CP is greater than or equal to default probability threshold (0.4), double threshold before its counted as 'cloud'\n",
    "3. Generate two separate cloud masks.\n",
    "   * Where 10th percentile is >= `cp_10th_percentile_threshold`, double probability threshold before declaring as cloud.\n",
    "   * Where 10th percentile is < `cp_10th_percentile_threshold`, use default S2Cloudless probability threshold (0.4)\n",
    "5. Calculate geomedians and compare.\n",
    "\n",
    "\n",
    "`Option 2 (less conservative, easier to implement)`\n",
    "1. Load long-term cloud probabilities (say five years), take the 10th percentile.\n",
    "2. Add 0.4 (the default threshold) to the long-term percentiles and this is the new cloud-probability threshold.\n",
    "3. In regions where bright targets don't confuse S2cloudless, the threshold will still be 0.4 (or close to 0.4), in regions where the targets are commonly confused, the threshold will be substantially higher.\n",
    "4. Clip the maximum threshold to 0.95\n",
    "\n",
    "`Option 3: Synthesis of option 1 and 2`\n",
    "1. Load long-term cloud probabilities (say five years), take the 10th percentile.\n",
    "2. Where 10th percentile CP is greater than or equal to 0.1, Add 0.4 (the default threshold) to the long-term percentiles and this is the new cloud-probability threshold\n",
    "3. Clip the maximum threshold to 0.95\n",
    "\n",
    "Morphological filtering:\n",
    "* Using odc `mask_filters` approach for now rather than s2cloudless's `opencv` approach for simplicity. s2cloudless approach applies smoothing to the probabilities layer first, and since we're seperating out probabilities for two different conditions, it gets awkward.\n",
    "\n",
    "https://github.com/sentinel-hub/sentinel2-cloud-detector/blob/711d86176416b5afc2960963777407062adf852f/s2cloudless/cloud_detector.py#L127\n",
    "\n",
    "<!-- # import cv2\n",
    "\n",
    "# average_over = 4\n",
    "# dilation_size = 2\n",
    "\n",
    "# def cv2_disk(radius: int) -> np.ndarray:\n",
    "#     \"\"\"Recreates the disk structural element from skimage.morphology using OpenCV.\"\"\"\n",
    "#     return cv2.circle(  # type: ignore[call-overload]\n",
    "#         np.zeros((radius * 2 + 1, radius * 2 + 1), dtype=np.uint8), (radius, radius), radius, color=1, thickness=-1\n",
    "#     )\n",
    "\n",
    "# disk = cv2_disk(average_over)\n",
    "# conv_filter = disk / np.sum(disk)\n",
    "# dilation_filter = cv2_disk(dilation_size)\n",
    "\n",
    "# s2cloudless does this:\n",
    "# cloud_masks = np.asarray(\n",
    "#     [cv2.filter2D(cloud_prob, -1, conv_filter, borderType=cv2.BORDER_REFLECT) for cloud_prob in updated_cloud_mask],\n",
    "#         dtype=np.uint8,\n",
    "#     )\n",
    "\n",
    "# cloud_masks = np.asarray(\n",
    "#     [cv2.dilate(cloud_mask, dilation_filter) for cloud_mask in updated_cloud_mask], dtype=np.uint8\n",
    "#     ) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfffc1f2-92d6-44c6-94c1-8dc00819cb45",
   "metadata": {},
   "source": [
    "### Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278ff04-10a3-485d-8c32-9f121c09217c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Calculate cloud probability percentiles\n",
    "# prob_quantile = prob_quantiles['oa_s2cloudless_prob'].sel(quantile=0.1)\n",
    "\n",
    "# # cloud mask for regions repeatedly misclassified as cloud \n",
    "# quant_mask = xr.where(prob_quantile>=cp_10th_percentile_threshold, True, False) \n",
    "# quant_mask_probabilities = s2_unmasked['oa_s2cloudless_prob'].where(quant_mask)\n",
    "# quant_mask_probabilities_mask = xr.where(quant_mask_probabilities>=s2cloudless_threshold*2, True, False)\n",
    "\n",
    "# # cloud mask for regions NOT repeatedly misclassified as cloud\n",
    "# nonquant_mask = xr.where(prob_quantile<cp_10th_percentile_threshold, True, False)\n",
    "# nonquant_mask_probabilities = s2_unmasked['oa_s2cloudless_prob'].where(nonquant_mask)\n",
    "# nonquant_mask_probabilities_mask = xr.where(nonquant_mask_probabilities>s2cloudless_threshold, True, False)\n",
    "\n",
    "# ## Combine cloud masks\n",
    "# updated_cloud_mask = np.logical_or(\n",
    "#     quant_mask_probabilities_mask, nonquant_mask_probabilities_mask\n",
    "#             )\n",
    "\n",
    "# # apply morphological filters\n",
    "# updated_cloud_mask_filtered = mask_cleanup(updated_cloud_mask, mask_filters=mask_filters).compute()\n",
    "\n",
    "# # Apply updated cloud mask to observations\n",
    "# s2_updated_masked = s2_unmasked[['nbart_green', 'nbart_red', 'nbart_blue']].where(~updated_cloud_mask_filtered)\n",
    "# s2_updated_masked = s2_updated_masked.drop_vars('quantile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5cf11-5b30-4730-8fbe-b803325f8b6b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# s2_unmasked['nbart_red'].isel(time=2).plot.imshow(size=6)\n",
    "# s2_masked['nbart_red'].isel(time=2).plot.imshow(size=6)\n",
    "# s2_updated_masked['nbart_red'].isel(time=2).plot.imshow(size=6)\n",
    "# (updated_cloud_mask).isel(time=2).plot.imshow(size=6)\n",
    "# updated_cloud_mask_filtered.isel(time=2).plot.imshow(size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb65cc-bf13-46af-9baa-be7b2e180cbd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# nonquant_mask.compute().plot()\n",
    "# nonquant_mask_probabilities_mask.sel(time='13-03-2022').squeeze().plot.imshow()\n",
    "# quant_mask_probabilities_mask.sel(time='13-03-2022').squeeze().plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97ac88d-4216-4027-8369-041113d4d81e",
   "metadata": {},
   "source": [
    "### Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6358b5-89e4-428e-ac81-eb26f289e742",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Add long-term 0.1 quantile to the default 0.4 threshold. But clip range to 0.95 so threshold can't\n",
    "# be larger than 95 %\n",
    "# enhanced_prob_thresh = (prob_quantiles['oa_s2cloudless_prob'].sel(quantile=0.1) + s2cloudless_threshold).clip(0, 0.95)\n",
    "\n",
    "# #create binary cloud mask \n",
    "# updated_cloud_mask = s2_unmasked['oa_s2cloudless_prob'] > enhanced_prob_thresh\n",
    "# updated_cloud_mask = updated_cloud_mask.drop_vars('quantile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26fd8bb-548e-4fb0-bb8e-086f5d960087",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # apply morphological filters\n",
    "# updated_cloud_mask_filtered = mask_cleanup(updated_cloud_mask, mask_filters=mask_filters).compute()\n",
    "\n",
    "# # Apply updated cloud mask to observations\n",
    "# s2_updated_masked = s2_unmasked[['nbart_green', 'nbart_red', 'nbart_blue']].where(~updated_cloud_mask_filtered)\n",
    "# s2_updated_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb618d-19c1-4e19-a48c-9a460b7ebbea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# s2_unmasked['nbart_red'].isel(time=2).plot.imshow(size=6)\n",
    "# s2_masked['nbart_red'].isel(time=2).plot.imshow(size=6)\n",
    "# s2_updated_masked['nbart_red'].isel(time=20).plot.imshow(size=6)\n",
    "# (updated_cloud_mask).isel(time=2).plot.imshow(size=6)\n",
    "# updated_cloud_mask_filtered.isel(time=20).plot.imshow(size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee28d681-ddd8-4a38-a83e-04f9ae9885b4",
   "metadata": {},
   "source": [
    "## Option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf23a9-9183-4f27-b544-7af0189d9dd1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "##---S2Cloudless means of filtering, works on numpy arrays but not dask arrays--------\n",
    "\n",
    "# average_over = 4\n",
    "# dilation_size = 2\n",
    "\n",
    "# cloud_probs = s2_unmasked['oa_s2cloudless_prob'].data.compute()\n",
    "\n",
    "# import cv2\n",
    "# def cv2_disk(radius: int) -> np.ndarray:\n",
    "#     \"\"\"Recreates the disk structural element from skimage.morphology using OpenCV.\"\"\"\n",
    "#     return cv2.circle(  # type: ignore[call-overload]\n",
    "#         np.zeros((radius * 2 + 1, radius * 2 + 1), dtype=np.uint8), (radius, radius), radius, color=1, thickness=-1\n",
    "#     )\n",
    "\n",
    "# def convolve_filter(ds, average_over=4):\n",
    "#     disk = cv2_disk(average_over)\n",
    "#     conv_filter = disk / np.sum(disk)\n",
    "#     return cv2.filter2D(ds, 0, conv_filter, borderType=cv2.BORDER_REFLECT)\n",
    "\n",
    "# def dilate(ds, dilation_size=2):\n",
    "#     dilation_filter = cv2_disk(dilation_size)\n",
    "#     return cv2.dilate(ds, dilation_filter)\n",
    "\n",
    "# # s2cloudless does this, smoothing the probabolity array which removes\n",
    "# # small cloud speckles. OpenCV does not work with dask!\n",
    "# smoothed_cloud_probs = np.asarray(\n",
    "#     [convolve_filter(cloud_prob, average_over=average_over) for cloud_prob in cloud_probs],\n",
    "#         dtype=np.uint8,\n",
    "#     )\n",
    "\n",
    "# updated_cloud_mask_filtered = np.asarray(\n",
    "#     [dilate(cloud_mask, dilation_size) for cloud_mask in updated_cloud_mask], dtype=np.uint8\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b1462b-9e3d-4ca4-835a-101ef1392119",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_threshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1d454-f9d8-41f9-a76c-d064dc818762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 10th CP percentiles\n",
    "cp_10th_percentile = prob_quantiles['oa_s2cloudless_prob'].sel(quantile=0.1)\n",
    "\n",
    "#this should work but was failing weirdly...\n",
    "# updated_cloud_mask = xr.where(cp_10th_percentile > cp_threshold, #where 10th % cp is above 0.1:\n",
    "#             s2_unmasked['oa_s2cloudless_prob'] > (cp_10th_percentile+s2cloudless_threshold).clip(0, 0.95), # threshold probability by 0.4 + cp_10th_%\n",
    "#             s2_unmasked['oa_s2cloudless_prob'] > s2cloudless_threshold, #otherwise just threshold using 0.4\n",
    "#                              ).drop_vars('quantile')\n",
    "\n",
    "# cloud mask for regions repeatedly misclassified as cloud \n",
    "quant_mask = xr.where(cp_10th_percentile>cp_threshold, True, False) \n",
    "quant_probabilities = s2_unmasked['oa_s2cloudless_prob'].where(quant_mask)\n",
    "quant_probabilities_mask = xr.where(quant_probabilities>=(cp_10th_percentile+s2cloudless_threshold).clip(0, 0.90), True, False)\n",
    "\n",
    "# cloud mask for regions NOT repeatedly misclassified as cloud\n",
    "nonquant_mask = xr.where(cp_10th_percentile<=cp_threshold, True, False)\n",
    "nonquant_probabilities = s2_unmasked['oa_s2cloudless_prob'].where(nonquant_mask)\n",
    "nonquant_probabilities_mask = xr.where(nonquant_probabilities>s2cloudless_threshold, True, False)\n",
    "\n",
    "## Combine cloud masks\n",
    "updated_cloud_mask = np.logical_or(\n",
    "    quant_probabilities_mask, nonquant_probabilities_mask\n",
    "            )\n",
    "\n",
    "# apply morphological filters\n",
    "updated_cloud_mask_filtered = mask_cleanup(updated_cloud_mask, mask_filters=mask_filters)#.compute()\n",
    "\n",
    "# Apply updated cloud mask to observations\n",
    "s2_updated_masked = s2_unmasked[['nbart_green', 'nbart_red', 'nbart_blue']].where(~updated_cloud_mask_filtered)\n",
    "s2_updated_masked = s2_updated_masked.drop_vars('quantile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa95f9c-0b80-43ce-b465-b653f621691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2_unmasked['nbart_red'].isel(time=38).plot.imshow(size=6, vmin=0, vmax=3000)\n",
    "# s2_masked['nbart_red'].isel(time=38).plot.imshow(size=6, vmin=0, vmax=3000)\n",
    "# s2_updated_masked['nbart_red'].isel(time=38).plot.imshow(size=6, vmin=0, vmax=3000)\n",
    "# updated_cloud_mask.isel(time=38).plot.imshow(size=6)\n",
    "# updated_cloud_mask_filtered.isel(time=38).plot.imshow(size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6423e0-aa8d-4a7b-be76-16ba11fdfdc6",
   "metadata": {},
   "source": [
    "## Geomedians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5c0b86-ed9e-4181-a7d8-4538b03beb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard GM with no additional filtering\n",
    "s2_gm_standard = geomedian_with_mads(\n",
    "    s2_masked,\n",
    "    reshape_strategy='mem',\n",
    "    compute_mads=False\n",
    ")\n",
    "\n",
    "s2_gm_standard = assign_crs(s2_gm_standard.load(), crs='EPSG:3577')\n",
    "\n",
    "## GM with additional filtering\n",
    "s2_gm_updated = geomedian_with_mads(\n",
    "    s2_updated_masked,\n",
    "    reshape_strategy='mem',\n",
    "    compute_mads=False\n",
    ")\n",
    "\n",
    "s2_gm_updated = assign_crs(s2_gm_updated.load(), crs='EPSG:3577')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afbb44-76ac-4cdf-9e71-289fc20c3d8c",
   "metadata": {},
   "source": [
    "### Difference in clear counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db85f2-a26d-4f1d-ba72-4338646be3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_count = (s2_gm_updated['count'].astype(np.float32) - s2_gm_standard['count'].astype(np.float32))\n",
    "diff_count = assign_crs(diff_count, crs='EPSG:3577')\n",
    "\n",
    "diff_count.plot.imshow(vmin=-5, vmax=5, cmap='RdBu_r', size=5)\n",
    "plt.title('Enhanced clear count minus original');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99259ed-8e9b-4c83-a96d-f89d7d6533c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_count.odc.explore(\n",
    "    vmin=-5,\n",
    "    vmax=5,\n",
    "    cmap='RdBu_r',\n",
    "    tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "    attr = 'Esri',\n",
    "    name = 'Esri Satellite',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ecab90-742b-4449-8a7d-1688c99316ed",
   "metadata": {},
   "source": [
    "### Count NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b001871-7783-4494-9c83-077fa493a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in ['nbart_red', 'nbart_green', 'nbart_blue']:\n",
    "    num_of_nans = np.sum(np.isnan(s2_gm_standard[b]))\n",
    "    if num_of_nans>0:\n",
    "        print(f'{num_of_nans.item()} NaNs present in standard masking {b}')\n",
    "    else:\n",
    "        print(f'standard masking {b} is clean')\n",
    "\n",
    "for b in ['nbart_red', 'nbart_green', 'nbart_blue']:\n",
    "    \n",
    "    num_of_nans = np.sum(np.isnan(s2_gm_updated[b]))\n",
    "    if num_of_nans>0:\n",
    "        print(f'{num_of_nans.item()} NaNs present in enhanced masking {b}')\n",
    "    else:\n",
    "        print(f'enhanced masking {b} is clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08587921-0984-4bd8-849a-dea3c2cd9faa",
   "metadata": {},
   "source": [
    "### Make NaNs appear pink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d27eb6b-4e82-48cf-85e8-b3b526059518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a boolean mask where NaNs. Can do this on a single layer \n",
    "#  because we masked for contiguity\n",
    "nan_mask = np.isnan(s2_gm_updated['nbart_red'])\n",
    "\n",
    "# Loop over each band and assign the pink value where the pixel is NaN\n",
    "#  10000 blue, 10000 red, 0 for green.\n",
    "for var in s2_gm_updated.data_vars:\n",
    "    if var=='nbart_red':\n",
    "        s2_gm_updated[var] = xr.where(nan_mask, 10000, s2_gm_updated[var])\n",
    "    if var=='nbart_blue':\n",
    "        s2_gm_updated[var] = xr.where(nan_mask, 10000, s2_gm_updated[var])\n",
    "    if var=='nbart_green':\n",
    "        s2_gm_updated[var] = xr.where(nan_mask, 0, s2_gm_updated[var])\n",
    "    \n",
    "# Same again but now for S2Cloudless\n",
    "nan_mask = np.isnan(s2_gm_standard['nbart_red'])\n",
    "\n",
    "for var in s2_gm_standard.data_vars:\n",
    "    if var=='nbart_red':\n",
    "        s2_gm_standard[var] = xr.where(nan_mask, 10000, s2_gm_standard[var])\n",
    "    if var=='nbart_blue':\n",
    "        s2_gm_standard[var] = xr.where(nan_mask, 10000, s2_gm_standard[var])\n",
    "    if var=='nbart_green':\n",
    "        s2_gm_standard[var] = xr.where(nan_mask, 0, s2_gm_standard[var])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edefe531-0325-4071-a42f-ac43900748da",
   "metadata": {},
   "source": [
    "### Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6da3d9-182c-4eef-9d96-f105223351a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_clear_updated = s2_gm_updated['count'].mean().item()\n",
    "mean_clear_standard = s2_gm_standard['count'].mean().item()\n",
    "\n",
    "min_clear_updated = s2_gm_updated['count'].min().item()\n",
    "min_clear_standard = s2_gm_standard['count'].min().item()\n",
    "\n",
    "max_clear_updated = s2_gm_updated['count'].max().item()\n",
    "max_clear_standard = s2_gm_standard['count'].max().item()\n",
    "\n",
    "print(f'Updated masking clear counts (min, mean, max) = {min_clear_updated}, {mean_clear_updated:.0f}, {max_clear_updated}')\n",
    "print(f'Standard masking clear counts (min, mean, max) = {min_clear_standard}, {mean_clear_standard:.0f}, {max_clear_standard}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e9e59c-d496-48ee-94f4-fb12929ce04d",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162aa196-e2f5-4201-8a4a-c46901553aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,2, figsize=(15,12), layout='constrained')\n",
    "vmin, vmax=10, 90\n",
    "\n",
    "#--------standard------------------------------\n",
    "s2_gm_standard[['nbart_red', 'nbart_green', 'nbart_blue']].to_array().plot.imshow(robust=True, ax=ax[0,0], add_labels=False);\n",
    "s2_gm_standard['count'].plot.imshow(vmin=vmin, vmax=vmax, cmap='magma', ax=ax[0,1], add_labels=False);\n",
    "\n",
    "ax[0,0].set_title(f'Standard masking')\n",
    "ax[0,1].set_title(f'Standard masking, clear count. Mean={mean_clear_standard:.1f}')\n",
    "\n",
    "ax[0,0].set_yticklabels([])\n",
    "ax[0,0].set_xticklabels([])\n",
    "ax[0,1].set_yticklabels([])\n",
    "ax[0,1].set_xticklabels([]);\n",
    "\n",
    "#--------updated------------------------------\n",
    "s2_gm_updated[['nbart_red', 'nbart_green', 'nbart_blue']].to_array().plot.imshow(robust=True, ax=ax[1,0], add_labels=False);\n",
    "s2_gm_updated['count'].plot.imshow(vmin=vmin, vmax=vmax, cmap='magma', ax=ax[1,1], add_labels=False);\n",
    "\n",
    "ax[1,0].set_title(f'Enhanced masking')\n",
    "ax[1,1].set_title(f'Enhanced masking clear count. Mean={mean_clear_updated:.1f}')\n",
    "\n",
    "ax[1,0].set_yticklabels([])\n",
    "ax[1,0].set_xticklabels([])\n",
    "ax[1,1].set_yticklabels([])\n",
    "ax[1,1].set_xticklabels([]);\n",
    "\n",
    "plt.savefig(f'/gdata1/projects/s2_gm/results/processed_figs/s2_gm_annual_{region_code[0]}_improvedcloudmasking.png', bbox_inches='tight', dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa6c58-698b-4788-8e62-b1fa81e8e587",
   "metadata": {},
   "source": [
    "## Interactive plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a39de-a4cb-4203-8f2f-92683b06e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vmin, vmax = s2_gm_updated[['nbart_red', 'nbart_green', 'nbart_blue']].to_array().quantile((0.01, 0.99)).values\n",
    "\n",
    "# assign_crs(s2_gm_updated, crs='EPSG:3577').odc.explore(\n",
    "#     vmin=vmin,\n",
    "#     vmax=vmax,\n",
    "#     tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "#     attr = 'Esri',\n",
    "#     name = 'Esri Satellite',\n",
    "# )\n",
    "\n",
    "vmin, vmax = s2_gm_standard[['nbart_red', 'nbart_green', 'nbart_blue']].to_array().quantile((0.01, 0.99)).values\n",
    "\n",
    "assign_crs(s2_gm_standard, crs='EPSG:3577').odc.explore(\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "    attr = 'Esri',\n",
    "    name = 'Esri Satellite',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f45c9-1df5-498c-ad25-3442901dd5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797af45-782d-482a-bb84-f51f40da600a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
